# 队列

![image-20201127150438948](https://gitee.com/wangigor/typora-images/raw/master/数据结构与算法-队列.png)

> 队列跟栈一样，是一种操作受限的线性表。刚好相反的是，队列是**先入先出，后入后出**的结构。
>
> 队列的操作包括**入队「enqueue」、出队「dequeue」**。
>
> 跟栈一样，队列可以用数组来实现，也可以用链表来实现。用数组实现的栈叫作顺序栈，用链表实现的栈叫作链式栈。同样，用数组实现的队列叫作**顺序队列**，用链表实现的队列叫作**链式队列**。

## 顺序队列

> 直接上代码。

```java
class ArrayQueue {

    private Object[] items;
    private int capacity;

    private int head_index = 0;
    private int tail_index = 0;

    public <T> ArrayQueue(Class<T> type, int capacity) {
        this.items = (T[]) Array.newInstance(type, capacity);
        this.capacity = capacity;
    }

    /**
     * 入队
     */
    public <T> boolean enqueue(T item) {
        //队列满了
        if (tail_index == capacity) {
            return false;
        }
        items[tail_index++] = item;
        return true;
    }

    /**
     * 出队
     */
    public <T> T dequeue() {
        //队列满了
        if (head_index == tail_index) {
            return null;
        }
        return (T) items[head_index++];
    }
}
```

但是有问题，元素入队出队之后，head和tail指针都会后移。导致后续的10容量，其实不能承载10个元素入队。

**需要进行数据搬移**。只需要对入队进行修改，入队发现tail指针指向队尾，而head没在队头，进行数据搬运。

```java
public <T> boolean enqueue_withMove(T item) {
    //队列满了
    if (tail_index == capacity) {
        if (head_index == 0) {
            return false;
        } else {
            //数据搬移 「逐个迁移」还是「新生成数组进行迁移」都可以。
            for (int i = head_index; i < tail_index; i++) {
                items[i - head_index] = items[head_index];
            }
            //更新指针
            head_index = 0;
            tail_index = head_index - tail_index;
        }

    }
    items[tail_index++] = item;
    return true;
}
```

这样增加了数据搬运之后，时间复杂度还是O(1)「摊还分析」。

但是入队性能依然会收到影响。可以使用循环队列进行优化。

![image-20201127163642735](https://gitee.com/wangigor/typora-images/raw/master/数据结构与算法-队列-循环队列.png)

> **就是把数组首尾「连接在一起」。「取余」。**
>
> 但是有一个问题：队空和队满怎么判断的问题。
>
> - head == tail时，队空。
> - tail下一个节点是head时，队满：( tail + 1 ) % capacity == head

```java
class CycleArrayQueue {
    private Object[] items;
    private int capacity;

    private int head_index = 0;
    private int tail_index = 0;

    public <T> CycleArrayQueue(Class<T> type, int capacity) {
        this.items = (T[]) Array.newInstance(type, capacity);
        this.capacity = capacity;
    }

    /**
     * 入队
     */
    public <T> boolean enqueue(T item) {
        if ((tail_index + 1) % capacity == head_index)
            return false;
        items[tail_index] = item;
        tail_index = (tail_index + 1) % capacity;
        return true;
    }

    /**
     * 出队
     * @param <T>
     * @return
     */
    public <T> T dequeue() {
        if (head_index == tail_index) return null;
        T resule = (T) items[head_index];
        head_index = (head_index + 1) % capacity;
        return resule;
    }
}
```

## 链式队列

> 链式队列实现方式跟链式栈的思路一样。
>
> 只是需要多一个tail节点的指针「方便入队操作」。

## 并发队列

> 并发队列和并发栈思路一样。
>
> 无锁并发栈使用cas自旋锁实现即可。
>
> 这里提供demo提供并发的链式队列

```java
@Data
class ConcurrentLinkedQueue {

    private Node head;

    private AtomicReference<Node> tailRef;

    private static Unsafe unsafe;

    static {

      	//初始化unsafe
        try {
            Field unsafe_field = Unsafe.class.getDeclaredField("theUnsafe");
            unsafe_field.setAccessible(true);
            unsafe = (Unsafe) unsafe_field.get(null);
        } catch (IllegalAccessException | NoSuchFieldException e) {
            e.printStackTrace();
        }
    }


    public ConcurrentLinkedQueue() {
        head = new Node("0");
        tailRef = new AtomicReference<>(head);
    }

    /**
     * 入队
     */
    public void enqueue(String i) {

        Node node = new Node(i);
        Node tail;
        for (; ; ) {
            tail = tailRef.get();

            if (tailRef.compareAndSet(tail, node)) {
                tail.setNext(node);
                return;
            }
        }
    }

    /**
     * 出队
     */
    public String dequeue() {
        Node head_next;
        Node next_head;
        for (; ; ) {
						//head没有后置节点
            head_next = head.getNext();
            if (head_next == null) {
                return null;
            }
          	//获取head的next.next作为新的head.next
            next_head = head_next.getNext();
            if (unsafe.compareAndSwapObject(head, Node.next_offset, head_next, next_head)) {
                head_next.setNext(null);
                return head_next.value;
            }
        }
    }


    @Data
    @ToString(of = "value")
    @RequiredArgsConstructor
    static class Node {

        @NonNull
        private String value;
        private volatile Node next;
        private static long next_offset;

        static {
            Unsafe unsafe;
            try {
								//获取unsafe实例
                Field unsafe_field = Unsafe.class.getDeclaredField("theUnsafe");
                unsafe_field.setAccessible(true);
                unsafe = (Unsafe) unsafe_field.get(null);

              	//获取next的偏移量
                next_offset = unsafe.objectFieldOffset(Node.class.getDeclaredField("next"));
            } catch (IllegalAccessException | NoSuchFieldException e) {
                e.printStackTrace();
            }


        }

    }
}
```

> 「如果使用哨兵，推荐使用双向链表，因为需要查找tail哨兵的前置节点」。
>
> head指针和tail指针初始化不能为空，否则两个节点做cas会有并发问题。
>
> 我这里对**head使用了直接引用**，**tail使用了原子引用**。因为创建了一个head的「哨兵」节点，对出队操作，其实就是修改head哨兵的next指向，采取了unsafe对next偏移量的cas方式，而入队，只需要修改tail指针指向就可以。

## 阻塞队列

> 阻塞非阻塞的区别，在于不能完成操作时，线程是否『阻塞』等待结果。比如入队队满时，出队队空时。
>
> 不论采用持续监测「while(true){}」还是LockSupport对thread进行监控操作。都可以。
>
> 这里就不展开了。

## Disruptor

> Disruptor是英国外汇交易公司LMAX开源的一款高性能内存队列，初衷是为了解决jdk内存队列的吞吐量小的问题。
>
> 基于Disruptor开发的系统单线程能支撑每秒600万订单，2010年在QCon演讲后，获得了业界关注。2011年，企业应用软件专家Martin Fowler专门撰写长文介绍。同年它还获得了Oracle官方的Duke大奖。
>
> 目前，包括Apache Storm、Camel、Log4j 2在内的很多知名项目都应用了Disruptor以获取高性能。

> 参考文档
>
> [美团-高性能队列Disruptor](https://tech.meituan.com/2016/11/18/disruptor.html)
>
> [Disruptor3.3.2源码解析](https://www.iteye.com/blog/brokendreams-2255720)
>
> [github-disruptor](https://github.com/LMAX-Exchange/disruptor/wiki/Introduction)

jdk提供了很多Queue「有链式、顺序式、阻塞式、TransferQueue、双端deque、并发式、优先级队列等等」。对于一个对性能要求高的内存队列来说，需要考虑：

- 线程安全
- 避免内存溢出「有界」
- 避免垃圾回收对性能的影响

能选择的只有ArrayBlockingQueue。

而ArrayBlockingQueue存在两个性能问题：

### 锁的性能问题

ArrayBlockingQueue采用的是ReentrantLock，带来了线程切换和阻塞等待的开销。



> 线程A、B争抢lock，没抢到的进行阻塞等待「park」，跟synchronized一样都是使用Mutex Lock实现的，阻塞和唤醒操作都需要进行内核态和用户态的切换。
>
> 说是开销，其实也只是一个ns级别的开销。「Most people have the misconception that locks are slow.」

且，带来了锁的粒度问题：

- 「**粒度大了**」如果加锁和解锁之间夹杂了「业务操作」：比如像数组中「锁定」位置填完数据之后再释放锁。那么未争抢到锁的操作线程等待时间会更加「恐怖」。
- 「**粒度小了**」可能「业务操作」的时间居然达不到阻塞等待时间的1/10。不禁要问，用这个锁干嘛。



解决方案就是「**自旋锁**」。

通过CAS，不阻塞线程，可以做到多个线程「ABCD」进来，顺序争抢到比如「0，1，2，3」四个位置，ABCD四个线程对「业务操作」不阻塞各干各的。

### 伪共享问题

<img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210706155828553.png" alt="image-20210706155828553" style="zoom:50%;" />

CPU有三级缓存「有的有4级缓存」。

- 一级缓存L1。分为L1I「指令缓存」和L1D「数据缓存」。离cpu核心最近，速度最快，也最小。
- 二级缓存L2。容量比L1大，速度也比L1慢。每个核心都有L2缓存。
- 三级缓存L3。容量更大，更慢。多个核心共享。

cpu读取数据时，先去L1查看，没有再去L2，没有再去L3，没有在通过总线读取内存数据。

| 从CPU到                                  | 大约需要的CPU周期 | 大约需要的时间 |
| :--------------------------------------- | :---------------- | :------------- |
| 主存                                     | -                 | 约60-80ns      |
| QPI 总线传输(between sockets, not drawn) | -                 | 约20ns         |
| L3 cache                                 | 约40-45 cycles    | 约15ns         |
| L2 cache                                 | 约10 cycles       | 约3ns          |
| L1 cache                                 | 约3-4 cycles      | 约1ns          |
| 寄存器                                   | 1 cycle           | -              |

虽然这仍然是一个很小的时间，但是从内存读取数据，仍然比从L1缓存中慢了将近两个数量级。

且，存在线程共享的变量时，共享变量的修改，需要通过「缓存一致性协议」穿透三层缓存修改内存，其他线程缓存失效，重新穿透三层缓存读取。

> 三层缓存的大小，可以通过命令行查看
>
> ```bash
> #linux
> getconf -a |grep CACHE
> ```
>
> ```bash
> # macos
> sysctl -a |grep cachesize
> ```
>
> ![image-20210706161327279](https://gitee.com/wangigor/typora-images/raw/master/image-20210706161327279.png)

另外还有一个缓存的加载优势，按行加载，每次都加载一个cache line「缓存行」。一个缓存行64字节，如果要读取一个long「8字节」数据，那么同时会同时加载后续的7个long长度的其他数据。

如果这7个数据没用，那可太难受了；如果刚好是后续操作需要的，那么就有缓存可用了。

> 这也是数组访问速度比链表访问速度快的原因之一。

```java
@org.junit.Test
public void test() {

    long[][] longs = new long[1024 * 1024 ][];
    for (int i = 0; i < longs.length; i++) {
        longs[i]=new long[8];
    }

    long l1 = System.currentTimeMillis();
    //利用缓存行读取
    for (int i = 0; i < longs.length; i++) {
        for (int j = 0; j < 8; j++) {
            long l = longs[i][j];
            //啥也不干
        }
    }
    long l2 = System.currentTimeMillis();
    System.out.println(l2-l1);

    l2=System.currentTimeMillis();
    //不利用缓存行读取数据
    for (int i = 0; i < 8; i++) {
        for (int j = 0; j < longs.length; j++) {
            long l = longs[j][i];
            //啥也不干
        }
    }
    long l3 = System.currentTimeMillis();
    System.out.println(l3-l2);
}
```

```测试结果
在2.4 GHz 八核Intel Core i9 64G内存的环境中测试结果
13
40
```

利用缓存行，快了一倍多。

注意。这里不仅可以使性能**提升**，而且也可能会导致**性能下降**。

> 比如ArrayBlockingQueue有两个个参数，大概率是在同一个缓存行中的。
> ```java
> /** items index for next take, poll, peek or remove */
> int takeIndex;
> 
> /** items index for next put, offer, or add */
> int putIndex;
> ```
>
> 假设生产线程A只需要操作putIndex，消费线程B只需要操作takeIndex。
>
> 应该各不影响。可以线程A修改putIndex，导致缓存行失效。线程B需要重新从内存加载。
>
> 这就导致了，本来只需要读取缓存行的1ns变成了从主存读取的60ns。导致了性能下降。

这个问题称为「**伪共享问题**」，应该使不同线程操作的元素不在同一个缓存行上，也就是增大元素之间的间隔。

> 这也是一种空间换时间的思想。
>
> 处理数组元素也是一样。不同线程如果操作不同数组元素，也可以增大间隔距离。

```java
interface Value {
    long increase();
}

@org.junit.Test
public void falseSharing() throws InterruptedException, ExecutionException {


    class PaddingValue implements Value {
        private long p1, p2, p3, p4, p5, p6, p7;
        public volatile long value = 0L;
        private long p9,p10,p11,p12,p13,p14,p15,p16;

        public PaddingValue() {
        }

        @Override
        public long increase() {
            return ++value;
        }
    }

    class NoPaddingValue implements Value {
        public volatile long value = 0L;

        public NoPaddingValue() {
        }

        @Override
        public long increase() {
            return ++value;
        }
    }

    class FalseSharingRun implements Callable<Object> {
        private final static long count = 50000000L;
        private Value[] values;
        private int arrayIndex;

        public FalseSharingRun(int handleIndex, Value[] values) {
            this.arrayIndex = handleIndex;
            this.values = values;
        }

        @Override
        public Object call() {
            long startTime = System.currentTimeMillis();
            for (long i = 0; i < count; ++i) {
                //自增一下
                values[arrayIndex].increase();
            }
            long endTime = System.currentTimeMillis();
            System.out.println("线程"+arrayIndex+"执行时间"+(endTime-startTime)+"ms");
            return null;
        }
    }

    int threadCount = 10;
    //初始化为paddingValue
    Value[] values = new PaddingValue[threadCount];
    for (int i = 0; i < threadCount; i++) {
        values[i]=new PaddingValue();
    }
    //初始化待执行任务
    ArrayList<FalseSharingRun> tasks = new ArrayList<>(threadCount);
    for (int i = 0; i < threadCount; ++i) {
        tasks.add(new FalseSharingRun(i,values));
    }
    //执行并等待执行完成
    List<Future<Object>> futures = ForkJoinPool.commonPool().invokeAll(tasks);
    for (Future<Object> future : futures) {
        future.get();
    }

}
```

```执行结果
# PaddingValue执行结果
线程3执行时间482ms
线程2执行时间483ms
线程1执行时间484ms
线程9执行时间493ms
线程4执行时间494ms
线程6执行时间497ms
线程7执行时间498ms
线程8执行时间500ms
线程5执行时间501ms
线程0执行时间504ms

# 改为NoPaddingValue执行结果
线程6执行时间4395ms
线程5执行时间4412ms
线程7执行时间5165ms
线程0执行时间5202ms
线程1执行时间5239ms
线程2执行时间5985ms
线程3执行时间6000ms
线程4执行时间6005ms
线程9执行时间6281ms
线程8执行时间6292ms
```

另:

在java8中使用**@Contended**也可以实现PaddingValue效果
```java
@Retention(RetentionPolicy.RUNTIME)
//可以注解在字段上，也可以注解在类上
@Target({ElementType.FIELD, ElementType.TYPE})
public @interface Contended {
  	//这里的value是分组组名，也就是同组内的不会分配在一个缓存行上
    String value() default "";
}
```

```java
/**
 * 改造NoPaddingValue
 * 增加@Contended
 * 并开启-XX:-RestrictContended
 */
@Contended
class NoPaddingValue implements Value {
    public volatile long value = 0L;

    public NoPaddingValue() {
    }

    @Override
    public long increase() {
        return ++value;
    }
}
```

```执行结果
线程7执行时间419ms
线程0执行时间427ms
线程8执行时间427ms
线程3执行时间431ms
线程4执行时间431ms
线程2执行时间431ms
线程6执行时间434ms
线程5执行时间436ms
线程1执行时间439ms
线程9执行时间443ms
```



