# 贪心、分治、回溯、动态规划算法

> 这是四种算法思想，不是具体的算法，而是用来指导我们设计算法和编码的思想。

## 贪心算法

> 贪心算法有一些经典应用，比如霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法等等。后面会逐个展开了解。

如何理解贪心算法，先看一个例子。

> 假设现有一个可以容纳100KG物品的背包，可以装各种物品。我们有以下 5 种豆子，每种豆子的总量和总价值都各不相同。为了让背包中所装物品的总价值最大，我们如何选择在背包中装哪些豆子？每种豆子又该装多少呢？
>
> | 物品 | 重量（KG） | 总价值（元） |
> | ---- | ---------- | ------------ |
> | 黄豆 | 100        | 100          |
> | 绿豆 | 30         | 90           |
> | 红豆 | 60         | 120          |
> | 黑豆 | 20         | 80           |
> | 青豆 | 50         | 75           |
>
> 思路：
>
> - 按照单价由高到低排列 「黑豆(4) > 绿豆(3) > 红豆(2) > 青豆(1.5) > 黄豆(1)」。
> - 依次占满：黑豆20KG -> 绿豆30KG -> 红豆50KG。

这是一个贪心算法的经典应用。他也反映了贪心算法的本质解题步骤：

- 当我们看到这些问题时，要首先想到贪心算法

  针对一组数据，设置了限制值和期望值。我们希望**从中选出一些数据，在满足限制值的情况下，期望值最大。**

  上面例子中限制值是100KG，期望值是 背包中物品的总价值。希望在满足背包中物品总重量不超过100KG的情况下，物品总价值最大。

- 模拟贪心算法

  **每次选择情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。**

  上面的例子就是，每次在剩余的豆子中，选择**单价最高**的豆子。

- 如果使用了贪心算法，是否是最优解。

  一般情况下，需要举几个例子验证一下。严格地证明贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。而且，从实践的角度来说，大部分能用贪心算法解决的问题，贪心算法的正确性都是显而易见的，也不需要严格的数学推导证明。

  **如果是最优解，我们才使用贪心算法。**

但是贪心算法并不一定是最优解。我举个栗子。

> <img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210302095309467.png" alt="image-20210302095309467" style="zoom:50%;" />
>
> 上图是一个有权图。找到一条从出发点S开始到T结束的路径，要求边的权重和最小。
>
> 按照贪心算法 选择S -> A -> E -> T「红线所示」1+4+4=9。
>
> 但是我们可以直观的看到权重和最小的路径是 S -> B -> D -> T「绿线所示」2+2+2=6。
>
> **贪心算法对于这个问题不是最优解。**原因是 **前面的选择，会影响后面的选择**。如果我们第一步从顶点 S 走到顶点 A，那接下来面对的顶点和边，跟第一步从顶点 S 走到顶点 B，是完全不同的。所以，即便我们第一步选择最优的走法（边最短），但有可能因为这一步选择，导致后面每一步的选择都很糟糕，最终也就无缘全局最优解了。

下面是几个贪心算法的例子。

### 分糖果

> 我们有 m 个糖果和 n 个孩子。我们现在要把糖果分给这些孩子吃，但是糖果少，孩子多（m<n），所以糖果只能分配给一部分孩子。
>
> 每个糖果的大小不等，这 m 个糖果的大小分别是 s1，s2，s3，……，sm。
>
> 除此之外，每个孩子对糖果大小的需求也是不一样的，只有糖果的大小大于等于孩子的对糖果大小的需求的时候，孩子才得到满足。假设这 n 个孩子对糖果大小的需求分别是 g1，g2，g3，……，gn。
>
> 我的问题是，**如何分配糖果，能尽可能满足最多数量的孩子？**
>
> 我们可以把这个问题抽象成，从 n 个孩子中，抽取一部分孩子分配糖果，让满足的孩子的个数（期望值）是最大的。
>
> 这个问题的限制值就是糖果个数 m。
>
> 我们现在来看看如何用贪心算法来解决。
>
> 对于一个孩子来说，如果小的糖果可以满足，我们就没必要用更大的糖果，这样更大的就可以留给其他对糖果大小需求更大的孩子。另一方面，对糖果大小需求小的孩子更容易被满足，所以，我们可以从需求小的孩子开始分配糖果。
>
> 因为满足一个需求大的孩子跟满足一个需求小的孩子，对我们期望值的贡献是一样的。我们每次从剩下的孩子中，找出对糖果大小需求最小的，然后发给他剩下的糖果中能满足他的最小的糖果，这样得到的分配方案，也就是满足的孩子个数最多的方案。

### 找零钱

> 这个问题在我们的日常生活中更加普遍。假设我们有 1 元、2 元、5 元、10 元、20 元、50 元、100 元这些面额的纸币，它们的张数分别是 c1、c2、c5、c10、c20、c50、c100。
>
> **我们现在要用这些钱来支付 K 元，最少要用多少张纸币呢？**
>
> 在生活中，我们肯定是先用面值最大的来支付，如果不够，就继续用更小一点面值的，以此类推，最后剩下的用 1 元来补齐。
>
> 在贡献相同期望值（纸币数目）的情况下，我们希望多贡献点金额，这样就可以让纸币数更少，这就是一种贪心算法的解决思路。直觉告诉我们，这种处理方法就是最好的。
>
> 注意。这些纸币的面额基本是翻倍的，类似于二分法「这种**面额设置方法还是挺讲究的**」。但是不是类比情况也同样试用贪心算法。我举个栗子。
>
> 有一个国家。纸币只有三种面额100，99，1「当然。你知道这是瞎编的。」。
>
> 我们需要凑出396，按照贪心算法需要三张100和96张1。按照动态规划可以得出4张99的最优解。

### 区间覆盖

> 假设我们有 n 个区间，区间的起始端点和结束端点分别是[l1, r1]，[l2, r2]，[l3, r3]，……，[ln, rn]。
>
> 我们从这 n 个区间中选出一部分区间，这部分区间满足两两不相交（端点相交的情况不算相交），最多能选出多少个区间呢？
>
> <img src="https://gitee.com/wangigor/typora-images/raw/master/f0a1b7978711651d9f084d19a70805cd.jpg" alt="img" style="zoom:50%;" />
>
> 这个问题的解决思路是这样的：我们假设这 n 个区间中最左端点是 lmin，最右端点是 rmax。
>
> 这个问题就相当于，我们选择几个不相交的区间，从左到右将[lmin, rmax]覆盖上。我们按照起始端点从小到大的顺序对这 n 个区间排序。
>
> 我们每次选择的时候，左端点跟前面的已经覆盖的区间不重合的，右端点又尽量小的，这样可以让剩下的未覆盖区间尽可能的大，就可以放置更多的区间。这实际上就是一种贪心的选择方法。
>
> <img src="https://gitee.com/wangigor/typora-images/raw/master/ef2d0bd8284c222b6e69294566a45b0e2b5-20210302105324235.jpg" alt="img" style="zoom:50%;" />
>
> 

### 哈夫曼编码 Huffman Coding

> 假设我们有1000个字符的文件，都是英文字母，一个字符占1个字节byte，也就是8bit。存储这1000个文件，需要8000bit，也就是7.8Kb。假设这1000个字符，只有a、b、c、d、e、f这6个字母。
>
> 我们知道三位二进制数，可以表示8个可能性。那么，这6个字母也就能表示成
>
> ```
> a（000）b（001）c（010）d（011）e（100）f（101）
> ```
>
> 每个字母只需要占3bit。那么整个文件经过「压缩」之后。只需要3000bit「2.9Kb」「如果不计算字典占用的空间的情况下」。
>
> 哈夫曼编码的本质第一条，也就是**对原数据进行拆分统计**。这里还没有用到贪心算法。
>
> 那么再来。还有没有更加有效的压缩效果呢。
>
> 让拆分后的字符频率也参与到压缩之中。**根据贪心算法，让频率更高的字符编码更短，频率更低的字符编码可以稍长**。
>
> 还是用上面的例子。a、b、c、d、e、f出现的频率分别是450、350、90、60、30、20。
>
> 编码有一个前提就是 高频率的**短编码不能**是低频率的**长编码**的**前缀子串**。不然区分不出来。最简单的方式可以如下编码
>
> | 字符 | 频率 | 编码   | 总bit数 |
> | ---- | ---- | ------ | ------- |
> | a    | 450  | 1      | 450     |
> | b    | 350  | 01     | 700     |
> | c    | 90   | 001    | 270     |
> | d    | 60   | 0001   | 240     |
> | e    | 30   | 00001  | 150     |
> | f    | 20   | 000001 | 120     |
>
> 总共需要1930bit。比刚才「压缩率」又更高了。
>
> 但是。上面的这一种新的编码方式，前面的0太多了。假设只有英文字母，如果文章中有超过8种以上英文字母，从第8种英文字母开始就需要用超过8bit表示，这还是只有英文字母的情况。那么假设文本中是我们常用的1500个汉字呢？
>
> 哈夫曼编码结合二叉树，采用了自下而上的二叉树构建方式。
>
> 以上面的例子为例：
>
> - 把所有的字符按照频率从低到高排列「直接放入优先级队列更方便。」
> - 取出两个优先级「频率」最低的，频率低的为左子节点，频率高的为右子节点。以『频率和』组成新节点放入优先级队列中。
> - 重复第二步。直到队列空。
>
> 还是用上面的例子
>
> - 先取出频率为20的f「f:20」和频率30的e「e:30」。组成的频率和为50的节点放回队列中。
>
> <img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210308221313439.png" alt="image-20210308221313439" style="zoom: 50%;" />
>
> - 取出优先级最高的两个 「50」和「d:60」。组成新节点「110」放回队列中。
>
>   <img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210308221813961.png" alt="image-20210308221813961" style="zoom:50%;" />
>
>   
>   
>   
>   
>   
>   
> - 取出优先级最高的「c:90」和「110」。组成新节点「200」放回队列中。
>   
>   <img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210308222126368.png" alt="image-20210308222126368" style="zoom:50%;" />
>   
>   
>   
> - 取出优先级最高的「200」和「b:350」。自称新节点「550」放回队列中。
>   
>   <img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210308222422975.png" alt="image-20210308222422975" style="zoom:50%;" />
>   
>   
>   
> - 取出最后的优先级最高的两个节点「550」和「a:450」。生成根节点「1000」。
>   
>   <img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210308222708231.png" alt="image-20210308222708231" style="zoom:50%;" />
>   
>   
>   
>
> 这样哈弗曼树就完成了。我们给「连接」标上0/1，左0，右1。从上到下，依次编码为:
>
> ```编码
> a 0
> b 11
> c 100
> d 1011
> e 10101
> f 10100
> ```
>
> 总共只需要1910bit就可以了。
>
> **而且不会出现短编码是长编码前缀子串的情况。因为字符节点都在叶子节点。**
>
> 由于上面数据的问题，缺失了一种情况，就是『频率和节点跳过了两个字符节点的情况』
>
> 假设频率和节点是『110』，队列中最小的两个字符节点是『e:70』和『f:60』就会出现这样的情况：
>
> <img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210308224009082.png" alt="image-20210308224009082" style="zoom:50%;" />
>
> 跟上面步骤的逻辑是一样的。

#### java代码实现

```java
/**
 * 生成哈夫曼字典 字符-哈夫曼二进制编码
 *
 * @param mainString
 * @return
 */
public Map<Character, String> getDictionary(String mainString) {
    //统计频率
    HashMap<Character, Integer> charFrequencyMap = new HashMap<>();
    for (int i = 0; i < mainString.length(); ++i) {
        char charAt = mainString.charAt(i);
        Integer frequency = charFrequencyMap.get(charAt);
        if (frequency == null) {
            charFrequencyMap.put(charAt, 1);
        } else {
            ++frequency;
        }
    }
    //添加进优先级队列
    PriorityQueue<Node> queue = new PriorityQueue<>(Comparator.comparingInt(o -> o.frequency));
    charFrequencyMap.forEach((character, integer) -> {
        queue.add(new Node(character, integer));
    });

    //组成huffman树
    while (queue.size() > 1) {
        Node left = queue.poll();
        Node right = queue.poll();
        queue.add(new Node(left, right));
    }
    //根节点
    Node root = queue.poll();
    HashMap<Character, String> dictionary = new HashMap<>();
    //递归编码
    encode(root, "", dictionary);
    return dictionary;
}

/**
 * 对有效节点编码
 *
 * @param node
 * @param preChar
 * @param dictionary
 */
private void encode(Node node, String preChar, Map<Character, String> dictionary) {
    if (node == null) {
        return;
    }
    if (node.isLeaf) {
        dictionary.put(node.aChar, preChar);
        return;
    }
    encode(node.left, preChar + "0", dictionary);
    encode(node.right, preChar + "1", dictionary);
}


/**
 * 节点
 */
@Data
static class Node {
    /**
     * 频率
     */
    private int frequency;
    /**
     * 字符
     */
    private char aChar;
    /**
     * 左、右子节点
     */
    private Node left, right;

    /**
     * 是否叶子节点 代替对aChar的空判断
     */
    private boolean isLeaf;

    public Node(Node left, Node right) {
        this.left = left;
        this.right = right;
        this.frequency = left.frequency + right.frequency;
        this.isLeaf = false;
    }

    public Node(char aChar, int frequency) {
        this.aChar = aChar;
        this.frequency = frequency;
        this.isLeaf = true;
    }
}
```

> 只实现到了字符串生成哈夫曼编码表。
>
> 生成的"0101010"这样的字符串，而不是bit，主要是因为java的原因。后续需要字符串转二进制写，可能使用bitmap进行「翻译」后的写操作。我就不实现了。

## 分治算法

>字面意思就是**分而治之**。
>
>将原问题**拆分**为多个**规模较小**，与原问题**结构相似**的**子问题**。递归解决这些子问题，在合并结果，得到原问题的解。
>
>与递归不同的是：**分治算法是一种处理问题的思想。递归是一种编程技巧。**分治算法一般都比较适合使用递归算法来实现。在分治算法的递归实现中，每一层的操作都得是一样的步骤：
>
>- 分解：将原问题分解成一系列子问题；
>- 解决：递归的求解各个子问题；如果子问题足够小，直接求解。
>- 合并：将子问题的结果合并成现问题结果。
>
>分治算法能解决的问题，有一定的前提条件：
>
>- 原问题**可以拆分**为具有**相同模式**的子问题。
>- **子问题可以独立求解**，子问题之间没有相关性。「这一点跟动态规划有明显区别。」
>- **具有分解终止条件**。足够小的问题可以直接求解。
>- **子问题可以合并成原问题**，且合并操作的时间复杂度不能太高。

下面举几个分治算法的例子：

### 归并排序

> 在排序那一节讲了归并排序。这里就不展开了。
>
> 将一个大数组「拆分」为两个小数组。递归对小数组进行排序「直到小数组中只有一个元素」。再对小数组进行和合并。

### 计算数据的有序度「逆序度」

> 在前面的排序中，有介绍过通过有序度来衡量排序的时间复杂度的方法。
>
> 那么**怎么求解一组数据的有序度「逆序度」呢？**
>
> 逆序度最笨的方法是，拿每一个元素，跟他后面的数据对比，看有多少个比它小的，记为数组k。把所有元素都遍历过之后，对k求和，得到逆序度。不过这样操作的时间复杂度是O($n^2$)。借助分治算法应该怎么求解呢？
>
> - 求解数组「A」的逆序对个数。
> - 将「A」分成前后两部分「A1」和「A2」。
> - 分别计算「A1」和「A2」的逆序度 「K1」「K2」
> - 再计算「A1」和「A2」之间的逆序对个数「K3」。
> - 数组「A」的逆序度就等于「K1+K2+K3」。
>
> 最难得一个问题，就是**如何快速计算出K3？**
>
> 这就要借助归并排序了。在归并排序的『合并过程』中，我们就可以计算出K3的值。

<img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210319102632779.jpeg" alt="image-20210319102632779" style="zoom:50%;" />

```java
public <T extends Comparable> int reverseDegreeCount(T[] array, int start, int end) {
    if (start >= end) {
        return 0;
    }
    int middle = (start + end) / 2;
    int leftCount = reverseDegreeCount(array, start, middle);//左侧逆序度
    int rightCount = reverseDegreeCount(array, middle + 1, end);//右侧逆序度
    int k = merge(array, start, middle, end);//交叉逆序度k
    return leftCount + rightCount + k;
}

public <T extends Comparable> int merge(T[] array, int start, int middle, int end) {
    int t = 0;
    int k = 0;
    int i = start;//左侧指针
    int j = middle + 1;//右侧指针
    T[] temp = (T[]) new Comparable[end - start + 1];
    while (i <= middle && j <= end) {
        if (array[i].compareTo(array[j]) <= 0) {
            temp[t++] = array[i++];
        } else {
            temp[t++] = array[j++];
            k += middle - i + 1;//统计i到middle之间，比array[j]大的元素个数
        }
    }
  	//左侧剩余
    while (i <= middle) {
        temp[t++] = array[i++];
    }
  	//右侧剩余
    while (j <= end) {
        temp[t++] = array[j++];
    }
  	//temp拷贝回array
    for (int s = 0; s <= end - start; ++s) {
        array[start + s] = temp[s];
    }
    return k;
}
```

### 平面中距离最近的点

> 平面中有n个点，需要找到距离最近的一对点。
>
> 总是有暴力匹配法这样的东西时间复杂度$O(n^2)$.
>
> 把前面的分治算法扩展到二维平面，需要下面的步骤：
>
> - 先对n个点按照「横坐标」排序
>
>   这里能选择的排序方式有很多，要求是排序的时间复杂度低、空间复杂度低、没有必要是稳定排序
>
>   可以选择**快速排序**「时间复杂度$O(nlogn)$、原地排序、非稳定排序」
>
>   <img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210407134538886.png" alt="image-20210407134538886" style="zoom: 33%;" />
>
> - 开始递归分治
>
>   将整个「区域」划分成左右两块「**LeftArea、RightArea**」。
>
>   分别计算两个区域的内的最近的点对距离，**取最小值「d = min ( minLeft , minRight ) 」。**
>
>   **「合并」：考虑 一个点在LeftArea「绿色」，另一个点在RightArea「红色」的情况。**
>
>   <img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210407221818671222.jpeg" alt="image-20210407221818671" style="zoom:50%;" />
>
>   - 把中线「mid」两边，跟mid距离大于d的点『刨除』。
>
>   - 遍历LeftArea中符合规则的点。「以p点为例」逐个与RightArea中符合要求的点计算「疑似最小距离」
>
>     这里的符合要求就是「横纵坐标的差，都小于d」。
>
>     不用担心，**这样符合要求的点最多只会有6个点**：
>
>     ​	根据鸽巢(抽屉)原理「把多于n个物体放到n个抽屉里，至少有一个抽屉里的物体数量大于等于2」
>
>     ​	那么。把右侧符合条件的不看，可以看成一个d*2d的长方形。把长方形6等分。
>
>     ​	<img src="https://gitee.com/wangigor/typora-images/raw/master/image-20210407224730172229.png" alt="image-20210407224730179" style="zoom:50%;" />
>
>     ​	长方形的对角线长度为 $\frac56d$≈d。那么根据前面的条件「点之前的距离最小为d」，如果存在第7个点，那么这个点到其中一个点的距离一定小于d，是前面条件不满足。
>
>     所以。这里可以认为是一个常量级的时间复杂度。
>
>   - 得到的最小距离跟d比较即可。
>   
> - 递归终止条件
>
>   左右集合中有小于等于三个元素的时候，就直接计算。

